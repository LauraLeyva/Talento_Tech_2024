{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Proceso de Decisión de Markov (MDP)"
      ],
      "metadata": {
        "id": "VHAnB06xBPSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Definicion de estados, acciones y recompensas\n",
        "estados = ['A', 'B', 'C']\n",
        "acciones = ['Arriba', 'Abajo']\n",
        "recompensas = np.random.randint(9, 10, size=(len(estados),len(acciones)))\n",
        "\n",
        "# Función de transición aleatoria\n",
        "def transicion_aleatoria():\n",
        "  return np.random.choice (estados)\n",
        "\n",
        "# Generación de datos\n",
        "estado_actual = np.random.choice(estados)\n",
        "accion = np.random.choice(acciones)\n",
        "nuevo_estado = transicion_aleatoria()\n",
        "recompensa = recompensas[estados.index(estado_actual), acciones.index(accion)]\n",
        "\n",
        "print(\"Estado actual:\", estado_actual)\n",
        "print(\"Acción tomada:\", accion)\n",
        "print(\"Nuevo estado\", nuevo_estado)\n",
        "print(\"Recompensa:\", recompensa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjMz9YJiA5LI",
        "outputId": "d09eb39a-1767-4c1c-8f9c-64a29bc84b09"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estado actual: C\n",
            "Acción tomada: Arriba\n",
            "Nuevo estado B\n",
            "Recompensa: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conceptos de MDP"
      ],
      "metadata": {
        "id": "ERuoZCyUBdrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_transiciones_aleatorias(self):\n",
        "        transiciones = {}\n",
        "        for estado in self.estados:\n",
        "            transiciones[estado] = {}\n",
        "            for accion in self.acciones:\n",
        "                # Crear una distribución de probabilidad aleatoria para los estados siguientes\n",
        "                probabilidades = np.random.dirichlet(np.ones(len(self.estados)))\n",
        "                transiciones[estado][accion] = dict(zip(self.estados, probabilidades))\n",
        "        return transiciones"
      ],
      "metadata": {
        "id": "5u6iaoSqL0Au"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Estados:\",estados)\n",
        "print(\"Acciones:\",acciones)\n",
        "print(\"Recompensas\",recompensas)\n",
        "print(\"Transiciones\",transiciones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH1tPLuBLbN2",
        "outputId": "a65826ad-c3e9-4d67-d299-082317bd2684"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estados: ['A', 'B', 'C']\n",
            "Acciones: ['Arriba', 'Abajo']\n",
            "Recompensas [[9 9]\n",
            " [9 9]\n",
            " [9 9]]\n",
            "Transiciones {'A': {'Arriba': {'A': 0.38582739155652596, 'B': 0.4645763627189129, 'C': 0.14959624572456123}, 'Abajo': {'A': 0.6934866646012546, 'B': 0.04354861731485599, 'C': 0.2629647180838892}}, 'B': {'Arriba': {'A': 0.04813592397644143, 'B': 0.3883862982611506, 'C': 0.5634777777624079}, 'Abajo': {'A': 0.1043643283787283, 'B': 0.31339436239625074, 'C': 0.5822413092250209}}, 'C': {'Arriba': {'A': 0.3111456286114163, 'B': 0.46904761871178247, 'C': 0.21980675267680108}, 'Abajo': {'A': 0.3764211244394667, 'B': 0.3621996955465935, 'C': 0.26137918001393984}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class MDP:\n",
        "    def __init__(self, estados, acciones, recompensas, transiciones):\n",
        "        self.estados = estados\n",
        "        self.acciones = acciones\n",
        "        self.recompensas = recompensas\n",
        "        self.transiciones = transiciones\n",
        "\n",
        "def calcular_valor_estado(mdp, gamma=0.9, theta=0.01):\n",
        "    valores = {estado: 0 for estado in mdp.estados}\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for estado in mdp.estados:\n",
        "            valor_previo = valores[estado]\n",
        "            # Calcular el nuevo valor del estado\n",
        "            valores[estado] = max(\n",
        "                sum(\n",
        "                    mdp.transiciones[estado][accion][nuevo_estado] *\n",
        "                    (mdp.recompensas[mdp.estados.index(estado)][mdp.acciones.index(accion)] + gamma * valores[nuevo_estado])\n",
        "                    for nuevo_estado in mdp.estados\n",
        "                )\n",
        "                for accion in mdp.acciones\n",
        "            )\n",
        "            # Actualizar delta\n",
        "            delta = max(delta, abs(valor_previo - valores[estado]))\n",
        "        # Salir del bucle si delta es menor que theta\n",
        "        if delta < theta:\n",
        "            break\n",
        "    return valores\n",
        "\n",
        "mdp = MDP(estados, acciones, recompensas, transiciones)\n",
        "valores_estados = calcular_valor_estado(mdp)\n",
        "print(\"Valores de los estados:\", valores_estados)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH-b5U35JO8H",
        "outputId": "396617ad-bb88-4c52-9661-043ad431c26d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores de los estados: {'A': 89.94490008160099, 'B': 89.9482439629119, 'C': 89.95155726180982}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def verificar_propiedad_markov(mdp):\n",
        "  for estado in mdp.estados:\n",
        "    for accion in mdp.acciones:\n",
        "      suma_probabilidades = sum(mdp.transiciones[estado][accion].values())\n",
        "      if not np.isclose(suma_probabilidades, 1):\n",
        "        return False\n",
        "    return True\n",
        "# Ejemplo de uso\n",
        "print(\"Cumple con la propiedad de Markov:\", verificar_propiedad_markov(mdp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbXCUWUkCt2T",
        "outputId": "7b63345c-77eb-4f1f-931d-6f7a71fc244d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumple con la propiedad de Markov: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_recompensa_promedio(mdp):\n",
        "    recompensa_total = 0\n",
        "    total_transiciones = 0  # Contador para el número total de transiciones\n",
        "\n",
        "    for estado in mdp.estados:\n",
        "        for accion in mdp.acciones:\n",
        "            for nuevo_estado in mdp.estados:\n",
        "                recompensa_total += mdp.recompensas[mdp.estados.index(estado)][mdp.acciones.index(accion)]\n",
        "                total_transiciones += 1  # Contar cada transición\n",
        "\n",
        "    # Evitar división por cero\n",
        "    if total_transiciones == 0:\n",
        "        return 0\n",
        "\n",
        "    return recompensa_total / total_transiciones\n",
        "\n",
        "# Ejemplo de uso\n",
        "print(\"Recompensa promedio por acción:\", calcular_recompensa_promedio(mdp))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R22iP5cTNOOr",
        "outputId": "80569bdb-5273-4a63-e86c-364e25fc4143"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recompensa promedio por acción: 9.0\n"
          ]
        }
      ]
    }
  ]
}